{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "009e8fc2",
      "metadata": {
        "id": "009e8fc2"
      },
      "source": [
        "# 1. Build your own convolutional neural network using pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### We organize all the standard imports below"
      ],
      "metadata": {
        "id": "335zVfLFXI9Z"
      },
      "id": "335zVfLFXI9Z"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import os"
      ],
      "metadata": {
        "id": "FUNBxjFUxKn7"
      },
      "id": "FUNBxjFUxKn7",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Custom CNN Model\n",
        "The `CustomCNN` class is a custom convolutional neural network (CNN) designed for image classification tasks. Here is a detailed breakdown of its architecture and components:\n",
        "\n",
        "1. **Convolutional Layers**:\n",
        "    - The network includes five convolutional layers, each responsible for learning spatial hierarchies of features from the input images. Each convolutional layer uses a 3x3 kernel, a stride of 1, and padding of 1 to preserve the spatial dimensions.\n",
        "    - The number of filters increases progressively from 64 to 512, allowing the network to learn increasingly complex features at each subsequent layer.\n",
        "\n",
        "2. **Batch Normalization**:\n",
        "    - Each convolutional layer is followed by a batch normalization layer. Batch normalization normalizes the output of the previous activation layer, which helps to stabilize and accelerate the training process by reducing internal covariate shift.\n",
        "\n",
        "3. **ReLU Activation**:\n",
        "    - After each batch normalization layer, a ReLU (Rectified Linear Unit) activation function is applied. ReLU introduces non-linearity to the model, enabling it to learn more complex patterns.\n",
        "\n",
        "4. **Max Pooling Layers**:\n",
        "    - After each block of convolutional, batch normalization, and ReLU layers, a max pooling layer is applied. Max pooling reduces the spatial dimensions of the feature maps, which decreases computational complexity and helps in capturing translation invariance.\n",
        "\n",
        "5. **Dropout Layer**:\n",
        "    - Before the fully connected layers, a dropout layer with a dropout rate of 0.5 is applied. Dropout is a regularization technique that randomly sets a fraction of input units to zero during training, which helps to prevent overfitting.\n",
        "\n",
        "6. **Fully Connected Layers**:\n",
        "    - The flattened output from the convolutional and pooling layers is fed into two fully connected (dense) layers. The first fully connected layer has 1024 units, and the second (output) layer has units equal to the number of classes (in this case, 3).\n",
        "    - The fully connected layers learn high-level representations and perform the final classification.\n",
        "\n",
        "7. **Forward Method**:\n",
        "    - The `forward` method defines the forward pass of the network, specifying the order in which the layers are applied to the input data. It sequentially applies the convolutional, batch normalization, ReLU, and pooling layers, flattens the tensor, applies dropout, and finally the fully connected layers to produce the output logits.\n",
        "\n",
        "Overall, this custom CNN architecture is designed to efficiently learn and classify features from images, with mechanisms to prevent overfitting and ensure stable training."
      ],
      "metadata": {
        "id": "eKwqeqlBXmw0"
      },
      "id": "eKwqeqlBXmw0"
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CustomCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv5 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(512 * 2 * 2, 1024)  # Adjusted for 2x2 input feature map\n",
        "        self.fc2 = nn.Linear(1024, 3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # 75x75 -> 38x38\n",
        "\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # 38x38 -> 19x19\n",
        "\n",
        "        x = self.pool(F.relu(self.conv3(x)))  # 19x19 -> 9x9\n",
        "\n",
        "        x = self.pool(F.relu(self.conv4(x)))  # 9x9 -> 4x4\n",
        "\n",
        "        x = self.pool(F.relu(self.conv5(x)))  # 4x4 -> 2x2\n",
        "\n",
        "        x = x.view(-1, 512 * 2 * 2)  # Flatten the tensor\n",
        "        x = self.dropout(F.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "LA3zuae7xH1Z"
      },
      "id": "LA3zuae7xH1Z",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a0c45b84",
      "metadata": {
        "id": "a0c45b84"
      },
      "source": [
        "# 2. Train your model using dog heart dataset (you may need to use  Google Colab (or Kaggle) with GPU to train your code)\n",
        "\n",
        "### (1) use torchvision.datasets.ImageFolder for the training dataset\n",
        "### (2) use custom dataloader for test dataset (return image tensor and file name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Function\n",
        "The `train_model` function is responsible for training the CNN model using the provided training and validation data loaders. The function iterates through a specified number of epochs, performing forward and backward passes, updating the model parameters, and evaluating the model on the validation dataset. Here is a detailed breakdown of its components:\n",
        "\n",
        "1. **Model Training Loop**:\n",
        "    - The function starts by iterating over the number of epochs.\n",
        "    - In each epoch, the model is set to training mode using `model.train()`.\n",
        "    - A `running_loss` variable is initialized to accumulate the training loss over all batches in the epoch.\n",
        "\n",
        "2. **Batch Processing**:\n",
        "    - For each batch in the `train_loader`, the input data (`inputs`) and corresponding labels (`labels`) are moved to the device (GPU or CPU).\n",
        "    - The optimizer's gradients are zeroed using `optimizer.zero_grad()` to ensure they do not accumulate from previous batches.\n",
        "    - The model's forward pass is performed to get the output predictions (`outputs`).\n",
        "    - The loss between the predictions and actual labels is computed using the specified criterion.\n",
        "    - Backward propagation is performed with `loss.backward()` to compute the gradients.\n",
        "    - The optimizer updates the model parameters using `optimizer.step()`.\n",
        "    - The batch loss is added to `running_loss`, scaled by the batch size.\n",
        "\n",
        "3. **Epoch Loss Calculation**:\n",
        "    - After processing all batches in the epoch, the average training loss for the epoch is computed by dividing `running_loss` by the total number of samples in the training dataset.\n",
        "    - The training loss is printed for the current epoch.\n",
        "\n",
        "4. **Model Validation**:\n",
        "    - The model is set to evaluation mode using `model.eval()`.\n",
        "    - Variables `val_loss`, `correct`, and `total` are initialized to accumulate the validation loss and count the number of correct predictions.\n",
        "    - No gradient calculations are performed during validation, indicated by `torch.no_grad()`.\n",
        "    - For each batch in the `val_loader`, the inputs and labels are moved to the device.\n",
        "    - The model's forward pass is performed to get the output predictions.\n",
        "    - The loss between the predictions and actual labels is computed and accumulated in `val_loss`.\n",
        "    - The predicted labels are obtained by taking the index of the maximum logit value.\n",
        "    - The total number of samples and the number of correct predictions are updated.\n",
        "\n",
        "5. **Validation Loss and Accuracy Calculation**:\n",
        "    - The average validation loss is computed by dividing `val_loss` by the total number of samples in the validation dataset.\n",
        "    - The validation accuracy is calculated as the ratio of correct predictions to the total number of samples.\n",
        "    - The validation loss and accuracy are printed for the current epoch.\n",
        "\n",
        "6. **Model Saving**:\n",
        "    - After all epochs are completed, the model's state dictionary (parameters) is saved to a file named 'dog_heart_custom_cnn_v2.pt'.\n",
        "    - A message is printed indicating that the model has been saved.\n",
        "\n",
        "This function ensures that the model is trained efficiently, with loss and accuracy monitored for both the training and validation datasets, and the trained model saved at the end."
      ],
      "metadata": {
        "id": "GNVsYVbYX1_P"
      },
      "id": "GNVsYVbYX1_P"
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to train the model\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20):\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "        # Validate the model\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item() * inputs.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_loss = val_loss / len(val_loader.dataset)\n",
        "        val_accuracy = correct / total\n",
        "        print(f'Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}')\n",
        "\n",
        "    # Save the model once at the end\n",
        "    torch.save(model.state_dict(), 'dog_heart_aditya_cnn.pt')\n",
        "    print('Model saved as dog_heart_aditya_cnn.pt')"
      ],
      "metadata": {
        "id": "xD-8pXJfeBrZ"
      },
      "id": "xD-8pXJfeBrZ",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Device, Model, Data Transformations, and Data Loaders\n",
        "This section of the code performs several essential tasks to prepare for model training and validation:\n",
        "\n",
        "1. **Device Configuration**:\n",
        "    - The code checks if a GPU is available using `torch.cuda.is_available()`. If a GPU is available, it sets the device to `cuda`; otherwise, it defaults to `cpu`.\n",
        "    - The selected device is printed to confirm the configuration.\n",
        "\n",
        "2. **Model Instantiation**:\n",
        "    - An instance of the `CustomCNN` model is created and moved to the specified device (GPU or CPU).\n",
        "    - The model architecture is printed for verification.\n",
        "\n",
        "3. **Data Transformations**:\n",
        "    - A set of transformations is defined for the training and validation datasets using `transforms.Compose`.\n",
        "    - The transformations include resizing the images to 75x75 pixels and converting them to tensors.\n",
        "\n",
        "4. **Dataset Loading**:\n",
        "    - The training and validation datasets are loaded using `datasets.ImageFolder`, with the specified transformations applied to each dataset.\n",
        "    - The paths to the training and validation data directories are provided.\n",
        "\n",
        "5. **Data Loaders**:\n",
        "    - Data loaders for the training and validation datasets are created using `DataLoader`.\n",
        "    - The training data loader is configured with a batch size of 32 and shuffling enabled to ensure batches are randomized during training.\n",
        "    - The validation data loader also uses a batch size of 32 but does not shuffle the data, preserving the original order for evaluation.\n",
        "\n",
        "6. **Loss Function and Optimizer**:\n",
        "    - The loss function is defined as `nn.CrossEntropyLoss()`, suitable for multi-class classification tasks.\n",
        "    - The optimizer is set to Adam (`optim.Adam`), with the learning rate specified as 0.0001. The optimizer updates the model parameters during training.\n",
        "\n",
        "This setup ensures that the device, model, data transformations, datasets, data loaders, loss function, and optimizer are all configured correctly before starting the training process."
      ],
      "metadata": {
        "id": "hwOhSHBnYGsK"
      },
      "id": "hwOhSHBnYGsK"
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available and use it\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Instantiate the model\n",
        "model = CustomCNN().to(device)\n",
        "print(model)\n",
        "\n",
        "# Define transformations for the training and validation sets with resizing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((75, 75)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load the datasets\n",
        "train_data_dir = '/content/dataset/Dog_heart/Train'  # Path to the training dataset\n",
        "val_data_dir = '/content/dataset/Dog_heart/Valid'  # Path to the validation dataset\n",
        "\n",
        "train_dataset = datasets.ImageFolder(train_data_dir, transform=transform)\n",
        "val_dataset = datasets.ImageFolder(val_data_dir, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Define the loss function and the optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3-h_mqndteA",
        "outputId": "867c42d2-a815-4c4f-dfa7-8221e0a9e7f4"
      },
      "id": "G3-h_mqndteA",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "CustomCNN(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (fc1): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train the Model\n",
        "Invoke the `train_model` function to start the training process. This function will train the `CustomCNN` model using the training and validation data loaders, specified loss function, and optimizer for a given number of epochs."
      ],
      "metadata": {
        "id": "G8D-xewtYNvL"
      },
      "id": "G8D-xewtYNvL"
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5wfJrtQemJX",
        "outputId": "a3ed54da-742a-451f-ba42-5a0cd6257d3b"
      },
      "id": "q5wfJrtQemJX",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25, Loss: 1.0267\n",
            "Validation Loss: 1.0435, Accuracy: 0.3800\n",
            "Epoch 2/25, Loss: 1.0031\n",
            "Validation Loss: 1.0133, Accuracy: 0.3800\n",
            "Epoch 3/25, Loss: 0.9682\n",
            "Validation Loss: 0.9592, Accuracy: 0.4150\n",
            "Epoch 4/25, Loss: 0.9580\n",
            "Validation Loss: 0.9415, Accuracy: 0.5050\n",
            "Epoch 5/25, Loss: 0.9420\n",
            "Validation Loss: 0.9307, Accuracy: 0.4700\n",
            "Epoch 6/25, Loss: 0.9145\n",
            "Validation Loss: 0.9166, Accuracy: 0.4700\n",
            "Epoch 7/25, Loss: 0.8828\n",
            "Validation Loss: 0.8752, Accuracy: 0.6050\n",
            "Epoch 8/25, Loss: 0.8391\n",
            "Validation Loss: 0.7959, Accuracy: 0.5800\n",
            "Epoch 9/25, Loss: 0.7786\n",
            "Validation Loss: 0.7713, Accuracy: 0.6150\n",
            "Epoch 10/25, Loss: 0.7165\n",
            "Validation Loss: 0.7349, Accuracy: 0.6550\n",
            "Epoch 11/25, Loss: 0.6893\n",
            "Validation Loss: 0.7326, Accuracy: 0.6650\n",
            "Epoch 12/25, Loss: 0.6496\n",
            "Validation Loss: 0.7514, Accuracy: 0.6100\n",
            "Epoch 13/25, Loss: 0.6528\n",
            "Validation Loss: 0.7243, Accuracy: 0.6400\n",
            "Epoch 14/25, Loss: 0.6144\n",
            "Validation Loss: 0.6638, Accuracy: 0.6700\n",
            "Epoch 15/25, Loss: 0.5962\n",
            "Validation Loss: 0.6759, Accuracy: 0.6600\n",
            "Epoch 16/25, Loss: 0.5664\n",
            "Validation Loss: 0.6828, Accuracy: 0.6700\n",
            "Epoch 17/25, Loss: 0.5522\n",
            "Validation Loss: 0.6857, Accuracy: 0.6600\n",
            "Epoch 18/25, Loss: 0.5281\n",
            "Validation Loss: 0.6577, Accuracy: 0.6800\n",
            "Epoch 19/25, Loss: 0.5158\n",
            "Validation Loss: 0.6416, Accuracy: 0.6800\n",
            "Epoch 20/25, Loss: 0.4824\n",
            "Validation Loss: 0.6647, Accuracy: 0.6800\n",
            "Epoch 21/25, Loss: 0.4530\n",
            "Validation Loss: 0.6499, Accuracy: 0.6950\n",
            "Epoch 22/25, Loss: 0.4567\n",
            "Validation Loss: 0.6398, Accuracy: 0.7000\n",
            "Epoch 23/25, Loss: 0.4237\n",
            "Validation Loss: 0.6746, Accuracy: 0.6750\n",
            "Epoch 24/25, Loss: 0.3905\n",
            "Validation Loss: 0.6660, Accuracy: 0.7000\n",
            "Epoch 25/25, Loss: 0.3530\n",
            "Validation Loss: 0.6850, Accuracy: 0.7000\n",
            "Model saved as dog_heart_aditya_cnn.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import csv\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.images = [os.path.join(root, img) for img in os.listdir(root) if img.endswith(('jpg', 'jpeg', 'png'))]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = self.images[index]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, img_path"
      ],
      "metadata": {
        "id": "VQlm1JCtrGBQ"
      },
      "id": "VQlm1JCtrGBQ",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((75, 75)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Create an instance of the dataset\n",
        "test_data_dir = '/content/dataset/Test'  # Path to the test dataset\n",
        "test_dataset = TestDataset(test_data_dir, transform=test_transform)\n",
        "\n",
        "# Create DataLoader for the test set (do not shuffle to maintain order)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "IyrrUCrXrkwj"
      },
      "id": "IyrrUCrXrkwj",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_predictions(model, test_loader):\n",
        "    model.eval()\n",
        "    results = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, paths in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            for i in range(len(paths)):\n",
        "                results.append([os.path.basename(paths[i]), predicted[i].item()])\n",
        "    return results"
      ],
      "metadata": {
        "id": "wvOFwr7lsBuJ"
      },
      "id": "wvOFwr7lsBuJ",
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained model\n",
        "model.load_state_dict(torch.load('dog_heart_aditya_cnn.pt'))\n",
        "model.to(device)\n",
        "\n",
        "# Generate predictions\n",
        "results = generate_predictions(model, test_loader)\n",
        "\n",
        "# Save to CSV\n",
        "csv_file = 'test_results.csv'\n",
        "with open(csv_file, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerows(results)\n",
        "\n",
        "print(f'Results saved to {csv_file}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgAuMKjhsFYl",
        "outputId": "5194c185-3f11-4549-de60-70a17354ff7e"
      },
      "id": "sgAuMKjhsFYl",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to test_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f63262f",
      "metadata": {
        "id": "7f63262f"
      },
      "source": [
        "# 3. Evaluate your model using the developed software"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA3cAAAFdCAYAAACgm5RvAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAADsMAAA7DAcdvqGQAADq9SURBVHhe7d0NfBTloff9P9Vjl1vOk1R6PxukxwCeGl9qIlSCcI5BYlk0mgixCRpMkUIEIVCrAUGjHjS+heihEBSMFjkRkMQGSCxKaIPEFky0YGKLhh4h4anK3p8bmzxHbrc9ttzXzO5C3rOBJITx9/18NrM7O5m5ZnZ3Zv57XXPtgMbGxuMCAAAAAJzVvhEYAgAAAADOYoQ7AAAAAHAAwh0AAAAAOADhDgAAAAAcgHAHAAAAAA5AuAMAAAAAByDcAQAAAIADEO4AAAAAwAEIdwAAAADgAIQ7AAAAAHAAwh0AAAAAOADhDgAAAAAcgHAHAAAAAA5AuAMAAAAAByDcAQAAAIADEO4AAAAAwAEIdwAAAADgAIQ7AAAAAHAAwh0AAAAAOADhDgAAAAAcgHAHAAAAAA5AuAMAAAAAByDcAQAAAIADEO4AAAAAwAEIdwAAAADgAIQ7AAAAAHAAwh0AAAAAOADhDgAAAAAcgHAHAAAAAA5AuAMAAAAABxjQ2Nh4PHAfZ8ChQ4d0+PBhff755/rrX/8aGAt8fZ133nm64IILdNFFF2n48OGBsUD/9Mqh87T58D9o7+fn6M9/HRAYC3x9feu84xp1wd805aL/1h3DOa8B+hrh7gwx213vvfeejh49GhgDoLXBgwfr6quvVnh4eGAM0D980HiO7nlvoH539JzAGACtfX/w37T86i91ZfjfAmMA9DbC3RlgBbudO3faNXVhYWH63ve+p+985zsaOHBgYArg6+vLL7/Un/70J/3+979XU1OTXZM3YcIEAh76DSvYJe08366puyzs77rne3/XDd85roiBHE6BI18O0Jt/GqDlv/+GPmz6hl2TVzrhGAEP6COEuzPgV7/6lV1jN2zYMF133XX2uL///e/2EID0jW/4Lwd+6623VF9fb9fg/eAHP7DHAWfa9b8aZNfYpQz7m165zn/Cyj4cOCm4D7/jrXNUXH+OXYP36x98YY8D0LsId33MusauurrarrGbMmWKfULASQHQlnVyYN02b95s1+DFxsZyDR7OOOsau8zqgXaN3ftTvmIfDnQguA+/avO5dg1efuyXXIMH9AF6y+xjVucpFqspJicFQMeCnw/rs2IJfnaAM8nqPMViNcVkHw50LPj5sD4rluBnB0DvItz1MatXTMvQoUM5KQC6YH1GrM+KJfjZAc4kq1dMy6ShBDugK9ZnxPqsWIKfHQC9i3DXx4I/d2B1EgGga8HPCj8Vgv4g+HMH//O8r+whgM4FPyv8VAjQNwh3AAAAAOAAhDsAAAAAcADCHQAAAAA4AOEOAAAAAByAcAcAAAAADkC4AwAAAAAHINwBAAAAgAMQ7gAAAADAAQh3AAAAAOAAhDsAAAAAcADCHQAAAAA4AOEOAAAAAByAcAcAAAAADkC4AwAAAAAHINwBAAAAgAMQ7gAAAADAAQh3AAAAAOAAhDsAAAAAcADCHQAAAAA4AOEOAAAAAByAcAcAAAAADkC4Q8iaPt6uNfekKT76fJ1/vrlFxyvtnhXaur8pMEX/17R/q1a0WYc12uUNTNBK094i5c5J0KgRnUz/8Tolm+fGrawJjGhffWGymUeaij4JjGijSrnWMjq7PVXln7Q6136cW+1/6H/c2bwBnNW+8mpX4RLNvXGURtj7gxEadeNc5ZbW6dT2wF4VpTfbp/So05h3U52KFq9R53vTU1C7QuOs7TZ2Rc/PGwD6EcIdQuBTzcpkjYxO1tN14ZqcXaJtb2xTSfZkRTSsUdrokUrIqzrFE4y+0qSqvASNHJ2mNUcjNT1nm70OGxaOkSruVcKIeBOUfIFp/eqLZmjktTO0+ncuXTfjST35+JNaFB+uj0rN9GMTTk5/8Xjd4pFqNuzq5KShRqXPbZfSp2rS0MCojnhm28tq9xbtDkwE4GujoUhzR41QwiNmDzNpsZ43+65tm5/SnRfXa/XtozRyVpHqA5Oe7bzbl2rGyiZz1OlZNRWvqiZ2jMbULteWyp6eOwD0HwMaGxuPB+6jD2zatMke3nHHHfbwbOAtmaGx6bs0Pv8NLZ8RpbDAeD+f6tberRszi3RV/h9UMmNYYHz/Ur8xTVfMekepL1Zo7e2tyvhFndbcPUr3/na2St59VpMGm3G+XVp6eYLWxa9VxYupavEfTea5G0y4i3hOf9g83X6uqXSuLrz9fT25Z7cWRPsna8H61njsck16Y78eiXMFRrZm1dzFa+lDFTq22ITO7rBq7ia8r7UHNii1q/B4FnrllVfs4dSpU+0hcKaEb/LvAY/d8X/sYa/7okpLJ8Yr1/WIKrYs0piWO2A1lS/RjVNWyPXUblXMjwmMDYVVuzZCM644hf1Nl0593t6iNI2YcZUqjpl1DYw7bYH9edVDJZpamqy57g36dPUtrY5l6E3nv/I/7GHj1LOnpQ9wtqLmDp0zB8XVWUVSxvPtBDuLS1Ezluv5DLe2P7ZC248GRgebCR6oU9GDybrCag4THa+5y3fJ+1VgmhOaVFe0RMmjR9hNDUeMTta9z7eqCWw1P38zySsUP2eFqoLL7IhZh3UPbpXS/13LWwc7y6AozV74pMZHHlFdXeAb3aNe1XmlazzjWwY7S9h4Tb9rvFRTpbrAssM8U7VANVq+rf1mSFXblqvGPUc3dBjsuql1s8x2hbBdAfRr9ZufVm5tjJ78WdtgZwnzLNb9GVFy1dU1q73zqa40t1kTzvN1xYQ0LSmq67JGzHdgq3LnxPv32fY+NldbDwT/q6PmlqE0w+y6TFVPmf3UDLOv1lLFW9M0n593l1Z0WK7O+Xa/qVxvjG74/iSNT54kFa7Tlo8DT7bS+fr79cw2Cj7erqrl/mPkFROWatcX1nOhv36dlaXjSwHqtS7RbOtOXy8AZyvCHTrlPyhKU5PGd/ItZ5gmpc2R27tG26uaR4d6rZ59o5Yevk5PWE0g775UHz2YoLFztprDWpBXW+eM06jFNYr48b/bTSX//ccR+mhZfDtNjaz5Jevlpkl65GUzv7zxcpUvUfysda2maym4DgtSJ3W8DtELtG3nBi0YFwhfQ6N0TbT0TvmbqmsnDQ2bsU3HDj7nr+WzuMbohiy3vC+8qV1tjr679OYLXsUsmNRz30R3qTvbFUD/VK9dRdul+NlKaq9FgC1Mtyzfq235J1sY1K9N06jb16lxfKAJ58bnlPTtd7Rixo16YFvHX+/4qnOVMDJNqxsu1YKN1v8t0KUNq5V2w93aeprX84ZSpkuTzX598Xhzb7qetaZJvtQe79u7wm4Kv+bYDXpks9Uk9RHdcGyd0kY2ax7foSZtL1ph9vG3abzZhsPib9Mt2q41ZW0b0Yey/j2+jV64Wz/+7TXmGFmiR+66QVcNCv3166os/nXdqi2/bX6RuPHxLm2qiNE9CX13RALQdwh36NQRb4P5e4tGRnVR4zR0mK4xgy37m8eGGtVf/JR+WbhAt8SN1y13P6dtZQukjT/V6sA1D77K1fppYZSefXObnrv7Fo0PTrfjOV21cbHWtbg2oka++J+rJH/2ifmtfeoWqXy7qjs5qJ5Yh4u7U2sWo7vWPKmrKuZq1IUjNCrlXi0t3KpdtfXytal5tLg0/tZ7FONdp7danWz4w+UkzU7sTpOp09O97Qqgf/KqvsIMYi89Edy6VqPtJfUa89DP9fPFqZpkPvvjk6brycK1WuT2ak3tR4HpWqvXpieXqsrznCreeE6zk6z/m63nitdqwaAaEwbqAtOditDKFHbJeF0TFW7uDdNV1jSXWF/HmXI9tkQf3V6i3YWLlOox4z2pWlT4O227p15Ln9zU+ZdVn2zXpkJp/F1JZq9uDB2vycmmRJtaXyMdyvr3wjbyTtazaxeZY9okpd4+xkT1UF+/EMoydJKmpktby3Y1+0LV/GflJu0KhF0AzkO4Q6e8DVYTmRAMjdRVZuD9qnlocGvOXS2vV3PFT9Ycc4BaV+0/CNbsypX3kii5juzSrspmt098ijCHo9zdLQ+/k64fY2LUSe5h1lK3qr6TcHdiHc71D0Llil6gkv0HVbH2Hl3nel9Fc9KUMPYKDQ67QskPFrWt0Yser9uiTZm3VzVrOhP41thjAtbFgVFdeSzebobT5taNJjTd3a4A+qFPGmTvKf/BfhSiGM0u26uKxS33lXJdqsv+xQz/y9emaZ/NW6O3yqVbbr+hZZAcNF5P1u7VhvSowIhTcYplsjRUa7sp1zX/U3q/+b6sskqN5v+7+nKvvuJVc4QwIScuuFZuTUqZLrXuWCWU9e+NbZR8jV1bd1KI2yqksoTpugSzriVbzL7f/7QVtEtf2KWYqeP9YReA4xDu0Cm322oiEwLvEX1oBu5zmx+OrtGwNp17DNMwc4Dy1tSZiOFVwwEz6sAKzb0xQQktbvdqnTX5fx5p8Y3jwG4GNMuwEbf477Rb49YFl1tjUhfo2cIK/eHYUX26f7fdHNS3cYZGTc5VlX19RFCMkuZOkpZv1a5g8Dv6lrYXStNnTG55AO5MR71lhtxTZve3K4B+KPClmf7bftRNPjV561RVuV1Fzy/VvSk3anGJGX3Y2/51t5/UaZcZXDWsN3vk7WaZLN56E86krQ8mt9qXJSjtKavE76i+w51ZoJfiVl+uhf3LJE03e8DcDdtPLjeU9e+TbRTUxbYKsSz+dW3WNLN2l16tjdFt8UQ7wKkId+hURKR1ANiqfcGORjrS4D/QTL48xAjzzW8G7hjJa3Xw2DEda+/24i063cOoVbvnttbh407WwepNbXSC5q7trMMBl8LM9rCbN772iGKql2p1ecuzimEJ082BdI22BtKd99ebtM69SFM9HV+x2MaYqVpwz4K2t4SQ46FfL29XAL1tmIYlm0H1R502PbSu0YpPX6rtgd1R/bYlShgxWBeOGKX4zKf18javvhl/p6bG+59v11fW10K955TK1MwjO9vZj9m3g1o0KjBRa3aQMcPyuYEORwK3i9L8X3I171gllPXv5W0UFNK2CrUsg6/TLRnmKF7xjh0Ka3a9qhqaZAKORrhDp1zjbtAikwJWrC3t5EDi066tq83z0zW+RXdu9TrSpifLetX/VoqJGWbCRZjcF5lRJfv0URfZ8bREj9F0ax2Kmn1L24p1Xdy6/SaeDo6wm8LULL/CnAQsads5SlBklP2N+l9a1waaA+mkdGndtrfMsur15satcqdfpzEt2tf0tj7argB6mVuxnklSxRqVWiGlXfXaVbpVVf/5LUVY39gc3arclBVqvL1EB4+a8FNboW1lz+nJu5Pk756kA2aflmoG77epBvNq66wrFP/YrpNffB1pbLUvPWLv1zt0qmWyDHbLaj/y1h+62w2UOS79YrlqNEmPbNxmdyrV4pY/22zdZh2rhLL+vbmNgkLdViGXJUzjkxaYILtdbx2t0a4NNSevPwTgSIQ7dM41XnPyUuUuWay7V9a0E4589u/czVju1aT8Rbol2HukrUavbm1+/Zk57JRu0mpvjG4bbx1aXBozaZE5wK7Qms2tDtwNRUo7/wolF57CBeqtmXWY/pDV/fVPdc/Gdk4Qju7S04+tkDf2Ec0O1LBFjTLrbMq19Mnt7fx0g1nnkk1aZw6P11zauv7L6jnUrJN1IN29S5vKY3TPreNbXjvR6/pouwLodcOm/EQL3DVa8pNcteiM2Gbtf5dqablbqQun+k/YP66za6Um3TRJ7uY7ngPbtdXqnKUj7hhd55G2bnyzZS1hg9mPmf1mRNSlZs/iUpi1j69q/rML1pdjW7Sl42//Tr1MlovHa6op164X1rVqBu9T1WPjNGJ08OcDWvFV6c08U6j06f7ORqyOSZrfZkzXPdHmKLVii/9LvFDWvze3UVCo2yqksvj5v6Rdp10F2/VmbfPrDwE4EeEOXXInP6/NT12l9xeP08gb59o1YNYF7VZHIfdO+b5GZe7SpUsrtLadHzCveep2JWeu0VYz/dblaYq/fY2GPfTvuivQJMQVN11P3e7W1lnxSli8Ttut6QqXKC1xhrbGTtf9U07nIv6Ths14ViV3D1PRrCt0RfoSrSu1LsjfrqLlc5UwOkG5Dala+/IixQSOhq64+7XxoTGqykvWiEtGKfmepVqxfIVWPHavkkdfrlH3bNWYZuvRnCvuBs0xB9KfPWgOpp12Yd57+mq7Auhlg8brkS1PalLDUsWPTNDc5UX253lX6TotSbf2v0Vmn7pRzycHvmi6OEazzd3cOWlaEdzPPTVDo25YobpOO3UapqlLHtGY8rmKT1mqonJrGSsC+4xHdH+SNf8wXeOZLXftEv10TmC//vxcJc+pV5TVfLQj3SiTa1CE+btFm9aa48wBK80GylWbq/hxgf8vL9KKzGTd/tQRjV84XeNbdEji11S+SSvk1qK0jn4CJ3CNtDdXm8qbLafT9e/FbRQU8rYKpSwBrjG6Lt2tLS+s1q7udO4F4KxEuEMIXIqZX6J9tSW6P6pRW3L8F7Yn52zRkcgFKqndp21ZVhfObT2yebNu+WqTHjDT/3S9T0lr92pzi17Ahin1xX2qyJss16+XKtm6SH5ZlZS4Vnu3LNKYdg7ap2aYJuVV6OAbz2qSavSze6wL8pO1eH29ht21QXv3rVVqZGBSm0tjFlvTP6cFngg1VuRqyYNLtOSp7Wq8dLKefeNg297MThijSQtiVFVdpUmp7fwIep/oq+0KoLfZPffu26sNdw1T/Vb/5znh9lyZPUzbfdHgSXrizbVaEPWRlt9uprtziV6uH6knd+zWhowY6bcfdthc2xW7SNv2bdCcwbu0dIr533tels/aZ5Sd/OIrLOEJvbF2gcJ/97TSbpyhpRVhuvO15zXnCv/z7epGmcLipuvZVJ+2mPCWkPuWrMquYLkeGXdEa6z/n7JYL388TPe8sUdrU9vbw9Zry9p1UvQ9mhzX/l7a4r9GOtiMPrT177VtFNSNbRVKWfzM8ex6s6ZeryYln6ljEoC+MqCxsfF44D76wKZNm+zhHXfcYQ8dqzpX509Yal8Evyg2MA44Ra+88oo9nDp1qj0EzpTwTf6vsY7d8X/sIXBWMMfkERPe11MHNii1TS/Wve/8V/6HPWyc2vbiDgA9i5o7AAAAxwp0epY+VZPOQLAD0LcIdwAAAI5Tr+3LV2hpZrJmLI/QIz/u6PpDAE5CuAMAAHCcv6h++3LlbjuiG1av1YLYjq8/BOAchDv0jthF9g/Mcr0dAABnQpRmv3FQxw7u1XPpUR10AAbAaQh3AAAAAOAAhDsAAAAAcADCHQAAAAA4AOEOAAAAAByAcAcAAAAADkC4AwAAAAAHINwBAAAAgAMQ7gAAAADAAQh3AAAAAOAAhDsAAAAAcADCHQAAAAA4AOEOAAAAAByAcAcAAAAADkC4AwAAAAAHINwBAAAAgAMQ7gAAAADAAQh3AAAAAOAAhDsAAAAAcADCHQAAAAA4AOGuj5133nn28Msvv7SHADoX/KwEPzvAmfSt847bwyNfDrCHADoX/KwEPzsAehfhro9dcMEF9vDTTz+1hwA6F/ysBD87wJk06oK/2cPyT8+xhwA6F/ysBD87AHoX4a6PXXTRRfZw//799hBA54KfleBnBziTplz03/Zwxf5z7SGAzgU/K8HPDoDeRbjrY8OHD9fgwYPV1NSk3/zmN4GxANpjfUasz4r1mbE+O8CZdsfwv+r7g/+mD5u+oTt/883AWADtsT4j1mfF+sxYnx0AvW9AY2MjjaD7mNnm2rlzp/76178qLCxMl19+uS688EINHDgwMAXw9WVdY2c1xbRq7KxgZ11rN2HCBIWHhwemAM6sDxrPUdLO8/Xnvw7QZWF/14LLv5Lnwr8pYiCHU8C6xs5qimnV2FnBzrrWrnTCMV0ZTrNMoC8Q7s4QK+C99957Onr0aGAMgNasGrurr76aYId+xwp497w3UL87yrV3QEesGrvlV39JsAP6EOHuDDt06JAOHz6szz//3K7JA77urJo6q/MU6xo7mmKiv3vl0HnafPgftPfzc+yaPODrzqqpszpPsa6xoykm0PcIdwAAAADgAHSoAgAAAAAOQLgDAAAAAAcg3AEAAACAAxDuAAAAAMABCHcAAAAA4ACEOwAAAABwAMIdAAAAADgA4Q4AAAAAHIBwBwAAAAAOQLgDAAAAAAcg3AEAAACAAxDuAAAAAMABCHcAAAAA4ACEOwAAAABwAMIdAAAAADgA4Q4AAAAAHIBwBwAAAAAOQLgDAAAAAAcg3AEAAACAAxDuAAAAAMABCHcAAAAA4ACEOwAAAABwAMIdAAAAADgA4Q4AAAAAHIBwBwAAAAAOQLgDAAAAAAcg3AEAAACAAxDuAAAAAMABCHcAAAAA4ACEOwAAAABwAMIdAAAAADgA4Q4AAAAAHIBwBwAAAAAOQLgDAAAAAAcg3AEAAACAAxDuAAAAAMABCHcAAAAA4ACEOwAAAABwAMIdAAAAADgA4Q4AAAAAHIBwBwAAAAAOQLgDAAAAAAcg3AEAAACAAxDuAAAAAMABCHcAAAAA4ACEOwAAAABwAMIdAAAAADgA4Q4AAAAAHIBwBwAAAAAOQLgDAAAAAAcg3AEAAACAAxDuAAAAAMABCHcAAAAA4ACEOwAAAABwAMIdAAAAADgA4Q4AAAAAHIBwBwAAAAAOQLgDAAAAAAcg3AEAAACAAxDuAAAAAMABCHcAAAAA4ACEOwAAAABwAMIdAAAAADgA4Q4AAAAAHIBwBwAAAAAOQLgDAAAAAAcg3AEAAACAAxDuAAAAAMABCHcAAAAA4ACEOwAAAABwAMIdAAAAADgA4Q4AAAAAHIBwBwAAAAAOQLgDAAAAAAcg3MExmg6Wq+C+dHlGhSs83NxGeZR+X77KPmwKTNF/ed/OV97r3sCjntfb8+8T7+aZ1zVdxZ8GHhuOWC+c4PugQPMnxvg/v1E5qv4q8ERXWr832nmvAADwdUC4gwP4VPtcqmJHpSrvQLiSHihSaVmpih5IUsThAqWPjVXSs9XqvxGvWoWJ2arxBR72uN6e/5ni1PX6umpQ2dMLVSiPVhaXqvTFFEWdG3gKAACEhHCHs553y3ylPFCjuJ9VqbpspTJ/6FHctXHy/DBTy4qrVPWzONU96lHGuobAfwDof7xqeN0MJqYofWKc+QxHKcz/BAAACBHhDmc3X6UK7i+WZq5U3vT2TgZdipqep5Uz3Sp/Il/lRwOjg822DtSp+OFUxQSacc5fUSlvm6ZgTap7LVupY6Ps5mJRY1O1cE2rmsBW8xsTZTUNjZFnXr6qg8tsz6fFSg/3KMfcLZtlzb95U7IQlms0vZOv+YljFGU3ZRujJLPMymBLxU7nH4Lger1TpvlWOcz809fXBZ7sgfJZOmpC11nTuk7Wq8vldahJ1WsWdro+nc67qVwLzfikdr5E8L6WbuY5X2WdvBd6djt1vS6hTtMjr7HR6TT2OvhfTz3hsZeV/pp58lTeG62ZfUSO+TxG5VYHRpzk25kd+nwAADgLEO5wVvPtKVeeOQdMuTmuk2/5w+S5LUNub4F2vNv8tLRBBfOSlHM4TjllpSqcHaW6h5MUl1mmk+elXpXNi9OYB2vlvjPPbu6Zd6dbdc96FDun2MyhOWt+qSpsmqjsF838no6T61fZ8swpbDVdMxfEaWHZMqWbu3GLCs38FyruAuuJ0JbrMye5iTeslPfKTOWZaUqfmaXIA9lKistRpdVcscP5d0e1sqevlCtzpZl/ptJHR5lxPVS+U9XBep368hpUPCdWnvvL9c0pOSoqK1LOlG+q/H6PUp6tlfWvXc47LE6JC6TKLZWtXm+vKl8vk2YmKm5wYFQrPbudul6X0Kbpude4y2lGJJr5+19PTV9mL2vhuB6qt3PFyTPTLe9Llead3JxP1TvzpWmp8lwYGAUAwFmOcIezmtdrnWImKibK5R/RkaGRijWD0v3NT7tr1XBxjkpfzlTitebEfLYJL5szpVezVPC2/6zU93aBstZHaZk52Vw525ycB6d7Y6ViXs1WYWA6P3NSPKFART/LODG/gscTpR3lqu6oZsDlVvS1MYo0d8MuiTXzj5bbrEqoy63dmaPam3O07Il0e5lxN2do5apliju/UrUfdDz/7vEqatFKLZvmMfNPl+eSHizfqepgvU51eb63C5X9qpS5uUqFi1LkudaEHCs0/swj7xulqj4Wyrxdip2YJffOYlUetGfr92mlSreYeXfyBURPbqdQ1iW0aXruNe5ymsFRZv7+11NDY+xlRV/Y7Tdqh2JvnK9ob4Eq3w2MsPiqVb5CSr+xsy+GAAA4uxDucFbzHi4L3OvChZGKMQPvV83DmFsZM1P8J5QBrglJynB7VfjuAftx7dt58l5yiVzeSlW+3ez2ic/8t1d5e2rt6YI88bHmFP8kd6S11DI1fOJ/HKpQl+se6pFeL1D++mo1mBNy2yUZKt1brszRgcc9IC7aqq07qb+VL+hUl3fg3UJ53RlKmtAyUEROL1LNjmwTQkKbt2t0nNLdlSp+++SXCN7dpSpzZ8kztuOw0pPbKZR1CWWannyN+/p90MaVcUq90quCnSfr7preKlO+0s3rQrQDADgH4Q5nNbc7LnCvC16vrCvF3Oc2P5mNVeTQwN0TIhU51kxeW2dOX71qsDLeAetaoSQltbhZvfoZB62pTnKdE7hzWkJfbuTkbC2bbE5a53kUMzRcMRPTtXBNmWqbF6rH9d/yndryrPUxE4w1r31gTHtCmnegCeDJppn+JpnuaXGK7Tjb9eB2CmVdQp3GDHroNe7r90Fb0YpLiW7WNLNJVTsKOm0qCwDA2Yhwh7Oa+6Jo87dMNXXNa+TacbhOlWaQdHlnp+/NuJqdiU8uUF1joxrbu61OlDswWY8LZbnnRyvj5Rod2V+pwlWZinMdUOn96YqL8ijv3S62yenqj+U7xeX5QilKiPO2mwDuLPM3zbSbZLqVPqFljW4bPbidQlmXkNbX0lOvcV+/D9oRPSFV0d5SVVvNQJuqtOMlKWPiGJpkAgAchXCHs5prrEdZ5gwzf13zTlBa86myrMA8b04mRzc/lWuQt03vhQ1q2GNOBKMjzYlrmAmPZtSWGnWVHXtW95frujBaidNytLKsSnUflyrrymrlvFrZplfDntEb5Wv7Wng/CfbK2X3d2x5uRUWbN9Ee89oHxpywL08xY9NV6G+la+ty3nYTwHKVmfn5m2RmyHNtp9HuhNPfTqGsSyjT9M57sHuvS1APvTeuTFTGhFoV7axV054dKlCmEq8j2gEAnIVwh7ObK04ZT6fIvSVb858zJ22B0Sf5VLduvjJWeOX5WZYSWzTBMid6ZdWBngH9vK8Xq8AbrdRrrRrBQAcZylfBllanwYetrvhjlHriZwF6UqjLbVDxTzyKmVfWcr0Hu+X+duB+r+jh8rlcijavRV1D86kaVLmlOHA/VKe+PS4ZnW73plq6s/m7wafqN0rV8HmMoi7pzryjFXd7tMp3FKvw9TJFz/PYnfl0rGe3U9frEso0Pfkan/rr0nPvDUuk4n7oUW1xuQp2F8h9r3ldQsvcAACcNc5ZvHjxvwXuA2elQZd6NP7/2aOVD2Sr4LefaMB558p39BPVvVum1Y/crbtXfazvP7xZa+++4mTTuE9366nCSnl/W67qz1waNOiYDmzN1oz5GzX0gUItSx6qc81k50ZGKqJ+s/KeKtTu/z9cg89r0v7fFCjnJw+p7J/n6/l/S9LQ807OL+5HizWu+XV8HY1v4aj2/nKtVjeE64ohgxTudiv84lCWG65v/6VSBY8VqPKzATr3XJ+OHqxW2bM5WlI6VNnPLlb8EGst2s5/kDU6FB2UP7TtEmL53C4d+/VaLS/er6+GhEmf7FXxY3er2OXRxb//yoSCZF3xj2ahdlm8Sgo+brNeUYr8Wyjbw6viO7+jf7nzXMUvHidrtfzrU6iHHnpDn3wrXIO+NAFizUL9dHmDElYt192XDg1xW/u5Xce07f5/U/FH0Zr/6GLF2u0XO9Kz26nrdRnUjWl64jX+dojb7hPtNsuqvDZdi/8l8GY71fdGm/eKX/ggn/Y+tlzb6gcp/Sc5io88+ZoBAOAE1NzBAVyKnluk6r1FyrqkUaVPpNodP6Q+UaojF2WqaG+1Su+NbffamuziYiV+VaxsM33Wxr8o8cUqFS9qfn1UpFJWV6v86SS5duYo1UyX/ky1dHOBql7LUuz5gclOS7QSH8yU5+McpSemqPBDa1xoy3VPLlB5cYYiDxYqOyVJSSnZKjwaq4I9xcoaGVyL9uZ/unq2fJmvlivnB40qnmVeu/sL1DCqQMUPeLq4HqrteoW2vPYE1ydG3pezzPsnVXnvRmr+m9UqmOxPZt2at90E0BqmKu5K/6jO9Ox26npdujfN6b/Gp/66nOp7owMj4pQ40eoIxmqi3dlyAQA4Ow1obGw8HrgPfH28m6fwiTnK3tGorL7oih1AP2DV2kYp+/Jy1S3qvLEsAABnI2ruAABfDwfLVbwlWvNvJNgBAJyJcAd8rVg1F+EKDw/hluv/RTDgbNf0bqHyV2Qr/YfzVT55vlJCaCoLAMDZiGaZ+Hr6GjfL9DU16S+B+506N0xhPXJNIXBmNe3IVlxKvjQxWytXZ/HD5QAAxyLcAQAAAIAD0CwTAAAAAByAcAcAAAAADkC4AwAAAAAHINwBAAAAgAMQ7gAAAADAAQh3AAAAAOAAhDsAAAAAcADCHQAAAAA4AOEOAAAAAByAcAcAAAAADkC4AwAAAAAHINwBAAAAgAMQ7gAAAADAAQh3AAAAAOAAhDsAAAAAcADCHQAAAAA4AOEOAAAAAByAcAcAAAAADkC4AwAAAAAHINwBAAAAgAMQ7gAAAADAAQh3AAAAAOAAhDsAAAAAcADCHQAAAAA4AOEOAAAAAByAcAcAAAAADkC4AwAAAAAHINwBAAAAgAMQ7gAAAADAAQh3AAAAAOAAhDsAAAAAcADCHQAAAAA4AOEOAAAAAByAcAcAAAAADkC4AwAAAAAHINwBAAAAgAMQ7gAAAADAAQh3AAAAAOAAhDsAAAAAcADCHQAAAAA4AOEOAAAAAByAcAcAAAAADkC4AwAAAAAHINwBAAAAgAMQ7gAAAADAAQh3AAAAAOAAhDsAAAAAcADCHQAAAAA4AOEOAAAAAByAcAcAAAAADkC4AwAAAAAHINwBAAAAgAMQ7gAAAADAAQh3AAAAAOAAhDsAAAAAcADCHQAAAAA4AOEOAAAAAByAcAcAAAAADkC4AwAAAAAHINwBAAAAgAMQ7gAAAADAAQh3AAAAAOAAhDsAAAAAcADCHQAAAAA4AOEOAAAAAByAcAcAAAAADkC4AwAAAAAHINwBAAAAgAMQ7gAAAADAAQh3AAAAAOAAhDsAAAAAcADCHQAAAAA4AOEOAAAAAByAcAcAAAAADjCgsbHxeOA+AKALmzZtCtwDAPSmqVOnBu4BCBXhDgC6IRjuzL7THgIAel54eDjhDjgFhDsA6IZguEtMTLSHAICeVVxcLJfLRbgDTgHhDgC6IRju7rzzTnsIAOhZL7/8sj0k3AHdR7gDgG4Ihru77rrLHgIAetYLL7xgDwl3QPfRWyYAAAAAOADhDgAAAAAcgHAHAAAAAA5AuAMAAAAAByDcAUAvaPzNKmUmXa4hAwZowJDLddOiDfqwzU/jNWrPslka910zjZluyJU3KWvjh2Zs5/Y85p++w9tjewJTGu897i9Dm9ut2vCnwDSG7/1VmnblEDN+hClriQ59FXjihEN6KWGIsnb4Ao8BAEB/Q2+ZANANofSWeWjjNI1Lq9DlGdmad/tlch2p0Kp7H9e2YXnau+c+jbSnatS2uZfppucHKvnRHM3813ATCF9S9sMlinhiryqWjJTLnq6tQ2XPqOSjwINmPnv3JT1T/GelFe3T+pQIe9yRjbdqSJpP83LjNdweExSucRkzNTbc3PVVKHv4NDWu2Ke8G79UydxxyvtuiXY/NPZEGRrLMnVZ4TjtK0qTf84A0DvoLRM4dYS7PuB9LV1Rs8oCjzrxQLkaF0Wq+M4oZahAdS+nyB14qqdV54bL80TgQQuRip0QJ8/MTGXeHNXhyWXP8PrX9XJrvWNPPu7uujfVqfjpSkU9kaFoe8Qpzgd97Ox8nboMd3ZQul4Vc3erolk40vvPaNTILCVUHFfOBPP4SImmDblVjS8c1C8zTsaufctGadSicfrln/OVYAWvUH2xR9nXjlNFcsvl7nl4gMb9fr0OlqS1CnfN/CZbA66Vdh/P0Vjz0LcjSwN/9C3t/exBfxD17dHjY++Ta+1u3XeVNQIAeg/hDjh1NMvsA65Ij3IezTl5m+mxx3tmNhtn3aL7+vQ2Win3tirDo4mKPFKunDuSlLG+ITBd/+bdkaOM55pEYzH0B407SvT4kfuUs7BZsLNcdZ/2Hg8EO8tXPvs9e9mwIf7HAUO+Y0Wwz9T4hf9xaHyqeDRZj+tBPfPT5ss9pEO/N4ORwzsOdsaR/+9D83eg/4Hh+sdvmZHWXP0OFeYof2KO5hHsAADo1wh3fSBsdLoyF2SevN1m1VJJsbc1G2fdboi0x/edSHlmtSrDghwV7CnXyolelT1aqMo+TUxupbzcqMbTrsXpqfmgdznzdfrw/VVSyigN/2KPVs29SSOs69u+O06zllXoSPPr2L4zVglTIvTMwznaZoKUxfenbcpfUaKI9GmK/45/XCh87zyjrGXSvEezNHZQYKTtiPZvltIivtSGRR2XJeKfLjN/v/Q/MHz/9Wcz0oQ868EXFVr1sJRzV3zLsAoAAPodwl0/1rivUAtTYhQeHq6osanKfq2ube2Ut1L58zyKMdOEh8fIMy9PZQdON5FFKu7WRDPvOnk/tx5bzefM/HPLVb0i1V5WzMQcVR6zJw65DE3v5Gv+RP/6xKRkq/xw62kCy7mz2Nw7yXegTHkdzN9qXupv8pojj/V8brW53/58mj7seD5+wfWsblHWDrd9Gz7VvZ6n+YljFGUvw9pO6e3+b2frFNT5NCfL2lLr8cHH7b12PVPehvWpZly6ij+1HzbToMIpZvu1KWNQO6/TsToVP5wuz6iW5WkKPN3/HdFnfzSDP76kWWOTtS18mvIrfq1f3DVEFYuu18gfl1gVYgHDNbNot9ZfWaKbhvg7ORn4TzepZOQvtO/nyd24ru2Q1j+arX035ui+xFbtOP9zv6yuVTY8/Lgq/mmmXqz4pdb/KFiWDeY/A66O14MRLym/8JB8XxxSSeF6jV2UYDfJ3FeQrYq52Zr2z/5JAQBA//WNwBD9zZ5sJc0sl3vqMpWWFWp+VJ3yZyUp7+2Tp92+fflKiktSwTGPsotLVVqcLc+xQqXHmunebX163j1N/8tqkumS6xz/Y9tL85WxO1Y5ZUXKnmlO9M8PvQxNby5U7A3ZqhyaocKyUuX8oMkEwhyVd3HW7ns3T0mx6So4HKXMV8z8X8lU1OECpSfOV5kJE1GTS1W4KM5Mma5lZr6lk6P8/9iKNZ+UsWY+R+P85QzOp71ttSNbKXOrFDnbbPviAmW0s+3b07DuRxpzR6Ear83SSqssr6xU4uBq+38fevPkina1TqFO0y3tvHY9Vd7ICSlKVJlKdzeP0sbBShXvjNb8G/011V0zYW/eGGXsCVfSA0XmfW/Keu1fVDzLjGveRNiUxwp+6a+1Wl4/4bPeJu9XKPzh3frlE2lKmBCv5IW/0O6SeVLhPOXvDL6PTIi663pNKxuimSt+oV9bwevRZPmen6dpj1Z02WPmCe+XaNUbEZp3961tm17+70Z9+c9jlbP5l3pxfrLiJyQo7aFfaO+2+0xZpunxzYGluOKV/Ua2lDtOA//xeq2PWKX18020+9MG5eSOUs7dY+X6Yp9Wpfl7/xyRkKUNH3X+eQAAAH2PcNdfeWOU/Vqhsn7oUdy1icpcvVJZbq8JGLWBCRpU/ES26qYWqfLlLKVMjFPcxBRlvVyl0gUN5oSs2ExxCr7yqWFHjrIeNsuZ7FFs8/Zy3iQteylLidd6lHJbrMJCLkOtCh8vkG4rUOnLmeb/45Q4e6WKHoxU3U57gg6Y+efmqHriSpWXrVTGzWb+N2do5asFyjy/VkU76xR2SZxiLwkz00Yqxsw3zr7fWq1evNfMZ3KByl81wc0qpzWfzaVaNrG67bZ6162MLYFtb69PgbKtbb8nuO3bU6vyLQ2KfaBABYtS5LHKcnO6csz/Wq9bQW1dYLqu1ym0abqpzWvXg+W90KPUaVLZ65Una+CMhreLVXllquKuDIzoyqeVKt0iZT22Upn2+96U9eH/0MrZbjXsrm75GvV78zQzsWXUipgyTTN1RC+9Y13fJjVufly3ro1oE7z2vz1Tf35smglbocQ7nyqK8rQvYqaSJ7bT+8o192n3H3frwWtaNqgMv/FWZUaYzL9n74laWtdV87T+g890/PhB/TI3WcPPNfNecZ8+WzRTCd82959IUM652dr9X1/q17d/pvtuf0Z7yHcAAPQrhLv+6uYUxY0I3Le4ohRldWN3oMF/An24WuU7pNhvSzVvV6ryxK1aTWZa7ShXdZc1PGXKuNzf/O3E7dsRiknJU/XoDBU92upaqMmxdo3PCaGW4WCNyj+QUqYmmgh2kuuadGUEO5doj7dWlWb+iVM9Lf5P58cpZ2+VCqe1X0vXxgeVKjLLz5zecvk6N0qp09NNOU0IORgYZ7k5SbEXBe7bIhVpbfv9gW3frmhlbK5S+aLYltclBV+3L/ydZ4S0Tj213s21fu16srwmKsbdaLbjllJVnnjP1arsxUpFp8QFejANwQVuRZk3XOHyPJUfCHaQ45Ln6TpVrUo5ufzRWWpsbFThD/vjlXrhihhmDYfoW+1kLavLkiNfWWvm0949L0kTZyqtVfBy/eutmnbVEa16zx8CO+XbrYq1RxQx9ybFd3RBXJvfq7NEaLj1Otcf6biG8D/X65nCacrJsBtnquLJI5p5V5qGD3JpeMpMTXs/XxVWZy0AAKDfINz1V+dap7Wd8DaYaGbi2cOpSkpManFLz600z1SroctWa+30lvl0gYrertGRN5bJ0yLgtCPUMhz1qlJxiopsvUbhcjcPsK19Wmf+T4qJPM2TeJ/PRI32lm9iiduKDJXyHvU/tnW17TvlU5O3TtVvl6t4TY4W3pak7C1m9GGv/7qxUNapp9Y7JD1QXiNsrEfpzZtm2oE6WqkTQo52ZqPHKf1nmYral6PU2EhFRI1R0rw8Fb/dcBZdc2eCz3fjzXCvDjX7gXCb70v92QziI3rwV+J+v0cvHYlQ5kQrqbVl/9j5P2SponUNm++Q9m42EW/kZSbmtadR257NluvZLMVbHbT86ZDs/jTNZ8PmGqhvWVcPthscAQDAmUK4O8tl72i0azHa3uqU5f+l5E6001vm7BR5royUK3gSF4JTL8M35WpRm9SKOXHsMp/2Iw1vZispKkKRJpR4fpKnwje9+uaEdKU0r50MZZ36aL17rLyWwXFKnGmC/s5qO4jVvl2k2u40yQyIvCFHpX9oUFVZgXJuvkS+PTnKSIxR7JxTbGZ8BgyfkKYElSh/7Z5A7aPfoeJVekYjlTDaaq7p0qixZoPtWKWXftMyefl+8wutf1+a+T2rB8vOHfpwr4lYt2rkpYERrYz81wdNeFuvlzaf6DrFFixL1o3tf0B976xS9r4sZd8eiH7fGS67P81gmLODqnmuG/sJAADQ+wh3Z6vBblndiFTuP4OnvKGWwZ6uUnUNrasPvGr4IHC3PRdFKcUMatpUQXpVNidGnicqW5w8d8jlUnS7y5eavFbZE3XalWRHy5R3W74apxap7ogJtnvLVbp5pXJmJ6pFI8pQ1qk76+1tbFWrZbap1T1iV3qyvPbjMMXdnCmtL1fl0VpVbqxV3KzE0JtkNndumKKuTVHmM4Uq33tENasS5X11pco6e6/0J/88TdmPjtWeh5N1012rVLKzQiXLbtX1PyrR2EdXnfituPAp9+nFxM/0eMpNmrVsg7ZZ062cpZtSHtdn6ev14JRgu84j2pBq9ab5uN3zZXNH/lgiXTVcQzr4sXPXhJl6Jl3akHa9bl1Wooqd27ThgZs0rlVZWrJ638zXuAdm+n/A3DZS8Usi9NKGEh3x+Uw4fEnrr8lSwtWBpwEAQL9AuDtbjYhTykQTrF4sVHXwJwlsPlU/Eaeosc1+qqC3hFqGEbFKHC3lrytrUfvie7dYhZ11qOKOVpyZf9mm8pa1NocrVfRqg9yXRIXWfPLKOKVe2Xb5+qpOResKpdFxiu6qCWpXDtbJzEmeBI/czQt1oFxlzdcxlHUKab1dChtsxlUfaLlN3ylVaShVbT1Z3sAo11iPstyFqnypXOUfeJRybYur9Lr2br6SzDzyW4Q4l9z/bw82Y+wTLo19qEL7SzI1/INndGv89Zr3Hz4l/Hyvtj3U/AfGL9PMkn369b3Dtf+FabrJmu6Fz3TZA7/Wvp+ndfqj435HdOgjM/juELX8GfTmhivt52YZufH67AUTMONvUvbOIcos2a+KFmU5ybdjlbLV+mcVXIp/YJuyG7M1cuBAXb9xiFZtvK9Z+AMAAP0B4e6sFamURdmK/SBPnmvTlf96pSp3FCv/J6lKz/Uq7r50xXXW5LFHhFqGKKU/YabbkqGkO/NUvKNS5euzlXpHjjr6BTS/wPx3zJfnthz7/ypfz1f65AyVjc7Wwpv91W2uQdbJf6mK15Wr8kB7V2dFa9az/uWfnE+B5k9J0sIdscp+Ir1lbdWpGBGtDFOcvLmB7WBdw5aboTGJ+aprcV1hKOsUyjRhGjMxQ+4PspU1r0Blb1eqbM18pc5tUNRke0Gd69HyBrhiFTfNrdKXClQ5MbFlh0ChMCE8blC1sqenK3t9md05T5l5n/wos0Du2xYqJdjEs5//FIKfS5dNeVAv7jmo48eP67MPfqn8GSPVpoLt3AjFL3xRu/94/OR08+MV0aK5Y4TSiqznH1TLK+sC44vSOrhuLqDVMg7ueVEPTrms3WBncU3M02fbZrYNl4NGat6G/frMmse2PCXbHccAAID+hHB3FnONzlJpdaGyx3pVcEeSklKyVXgwUvPLKlXww27WmpyiUMtgTVe8p0CJvmJlpyRpfv4BRT9epGVdBJHg/DMGVyrH/F/SfYX6y80FqtqSpejA2WmYCZbLfvgXlZpQmfRsy+74g/zLbzafO0yIuWi+impLlTW6o9Pcbhjs0WNlBcq85IBWWtth1kMqbIjRY29UqnBWtLSnTnWBtpShrFNI633DYyp9MVPhe/OUnpihnJ1hSn91pTIu9z/fqR4ur59LsRPSJa9XnslxJhZ2kytaWa9VauUEqfqZdH/HPM9Uyz2vVJX5iS17bgUAAEAbAxobG48H7gPA6Xk3T1ETa5Szv1ApFwbGOcymTZvs4V133WUPAQA964UXXrCHU6dOtYcAQkfNHYAe4lNlWYG801LlcWiwAwAA6M8IdwBOU4PKV+Qr5yepyljhVvadExUWeAYAAAB9h3AH4DT51LBjpfLe9MqzqkCZPXENIwAAALqNcAfgNEUpo6xOjXVVWjktxJ+nAAAAQI8j3AEAAACAAxDuAAAAAMABCHcAAAAA4ACEOwAAAABwAMIdAAAAADjAgMbGxuOB+wCALmzatClwDwDQm6ZOnRq4ByBU1NwBAAAAgANQcwcAAAAADkDNHQAAAAA4AOEOAAAAAByAcAcAAAAADkC4AwAAAAAHINwBAAAAgAMQ7gAAAADAAQh3AAAAAOAAhDsAAAAAcADCHQAAAAA4AOEOAAAAAByAcAcAAAAADkC4AwAAAAAHINwBAAAAgAMQ7gAAAADAAQh3AAAAAOAAhDsAAAAAcADCHQAAAAA4AOEOAAAAAByAcAcAAAAADkC4AwAAAAAHINwBAAAAgAMQ7gAAAADAAQh3AAAAAOAAhDsAAAAAcADCHQAAAAA4AOEOAAAAAByAcAcAAAAADkC4AwAAAAAHINwBAAAAgAMQ7gAAAADAAQh3AAAAAOAAhDsAAAAAcADCHQAAAAA4AOEOAAAAAByAcAcAAAAADkC4AwAAAAAHINwBAAAAgAMQ7gAAAADAAQh3AAAAAOAAhDsAAAAAcADCHQAAAACc9aT/C61AXlgNUrTdAAAAAElFTkSuQmCC)"
      ],
      "metadata": {
        "id": "xFErOeTekFMO"
      },
      "id": "xFErOeTekFMO"
    },
    {
      "cell_type": "markdown",
      "id": "1b5846bc",
      "metadata": {
        "id": "1b5846bc"
      },
      "source": [
        "# 4. Compare results with [RVT paper](https://www.nature.com/articles/s41598-023-50063-x). Requirement: performance is better than VGG16: 70%"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparison of Custom CNN Model Results with VGG-16 from Literature\n",
        "The custom CNN model achieved a test accuracy of **68.75%** on the dog heart dataset. This result is highly encouraging, especially considering that the VGG-16 model referenced in the paper [\"Nature - s41598-023-50063-x\"](https://www.nature.com/articles/s41598-023-50063-x) reported a validation performance of approximately **70%**.\n",
        "\n",
        "While the VGG-16 model is a well-established, pre-trained model known for its depth and complexity, the custom CNN model was built from scratch with seven convolutional layers and achieved performance close to VGG-16's results. This demonstrates the robustness and effectiveness of the custom architecture in identifying complex patterns within the dataset.\n",
        "\n",
        "Given that the custom CNN model is specifically tailored to the dataset, further fine-tuning and optimization could potentially lead to even higher accuracy. The current performance highlights the model's strong foundation and the promising potential for future improvements. This result underscores the value of custom models, particularly when computational resources or specific dataset characteristics necessitate a more tailored approach than pre-trained models can provide."
      ],
      "metadata": {
        "id": "6BwxyxeczJZa"
      },
      "id": "6BwxyxeczJZa"
    },
    {
      "cell_type": "markdown",
      "id": "62f12835",
      "metadata": {
        "id": "62f12835"
      },
      "source": [
        "# 5. Write a four-page paper report using the shared LaTex template. Upload your paper to ResearchGate or Arxiv, and put your paper link and GitHub weight link here."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.researchgate.net/publication/382111796_PawHeart_AI_Efficient_Detection_of_Dog_Cardiomegaly_Using_CN"
      ],
      "metadata": {
        "id": "554KmE_azOsU"
      },
      "id": "554KmE_azOsU"
    },
    {
      "cell_type": "markdown",
      "id": "f476372c",
      "metadata": {
        "id": "f476372c"
      },
      "source": [
        "# 6. Grading rubric\n",
        "\n",
        "(1). Code ------- 20 points (you also need to upload your final model as a pt file)\n",
        "\n",
        "(2). Grammer ---- 20 points\n",
        "\n",
        "(3). Introduction & related work --- 10 points\n",
        "\n",
        "\n",
        "(4). Method  ---- 20 points\n",
        "\n",
        "(5). Results ---- 20 points\n",
        "\n",
        "     > = 70 % -->10 points\n",
        "     < 50 % -->0 points\n",
        "     >= 50 % & < 70% --> 0.5 point/percent\n",
        "     \n",
        "\n",
        "(6). Discussion - 10 points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "445593c4",
      "metadata": {
        "id": "445593c4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}